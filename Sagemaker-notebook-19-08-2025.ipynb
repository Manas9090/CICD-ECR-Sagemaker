{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e1183e-7d63-4867-8ba9-17e32a91a832",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Model Deployment in Sagemaker #########\n",
    "##############################################\n",
    "import boto3\n",
    "from sagemaker.model import Model\n",
    "from sagemaker import get_execution_role, Session \n",
    "\n",
    "role = get_execution_role()\n",
    "session = Session()\n",
    "\n",
    "ecr_image = '491085388405.dkr.ecr.us-east-1.amazonaws.com/fraud-ecr-1908:v1'\n",
    "\n",
    "model = Model(\n",
    "    image_uri=ecr_image,\n",
    "    role=role,\n",
    "    sagemaker_session=session \n",
    ")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    endpoint_name='fraud-ml-endpoint'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7c0b53-8cc4-4139-b50a-28aca164038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: {\"predictions\":[0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## Inference using one row of Sample Data #########\n",
    "#########################################################\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create SageMaker runtime client\n",
    "client = boto3.client('sagemaker-runtime', region_name='us-east-1')  # update region if needed\n",
    "\n",
    "# Sample input — should match model's expected feature shape and order\n",
    "payload = {\n",
    "    \"inputs\": [[18.0, 1.0, 100987.0, 120870.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0]]\n",
    "}\n",
    "\n",
    "# Invoke the deployed endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName='fraud-ml-endpoint',  # Make sure this matches exactly\n",
    "    Body=json.dumps(payload),\n",
    "    ContentType='application/json'\n",
    ")\n",
    "\n",
    "# Read and decode the prediction\n",
    "result = response['Body'].read().decode('utf-8')\n",
    "print(\"Prediction:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212e76cf-5d5e-4177-bf4a-37bddfd58ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: {\"predictions\":[0,0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## Inference using two rows of Sample Data #########\n",
    "##########################################################\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create SageMaker runtime client\n",
    "client = boto3.client('sagemaker-runtime', region_name='us-east-1')  # update region if needed\n",
    "\n",
    "# Sample input — should match model's expected feature shape and order\n",
    "# payload = {\n",
    "#     \"inputs\": [[18.0, 1.0, 100987.0, 120870.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0]]\n",
    "# }\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        [18.0, 1.0, 100987.0, 120870.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0],\n",
    "        [25.0, 0.0, 200000.0, 150000.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Invoke the deployed endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName='fraud-ml-endpoint',  # Make sure this matches exactly\n",
    "    Body=json.dumps(payload),\n",
    "    ContentType='application/json'\n",
    ")\n",
    "\n",
    "# Read and decode the prediction\n",
    "result = response['Body'].read().decode('utf-8')\n",
    "print(\"Prediction:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac350dd-457a-48ec-bf72-00df5dac11ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model v2 Created: arn:aws:sagemaker:us-east-1:491085388405:model/fraud-model-v2\n"
     ]
    }
   ],
   "source": [
    "############ To create V2 of the End-point ##########\n",
    "#####################################################\n",
    "\n",
    "import boto3\n",
    "\n",
    "# Initialize SageMaker client (region must match your ECR/SageMaker)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=\"us-east-1\")\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "\n",
    "response = sm_client.create_model(\n",
    "    ModelName=\"fraud-model-v2\",\n",
    "    PrimaryContainer={\n",
    "        \"Image\": \"491085388405.dkr.ecr.us-east-1.amazonaws.com/fraud-ecr-1908:v2\"\n",
    "    },\n",
    "    ExecutionRoleArn=role\n",
    ")\n",
    "print(\"Model v2 Created:\", response[\"ModelArn\"]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4928666-56e4-42d5-84b7-0cce412326e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraud-model-v2\n",
      "fraud-ecr-1908-2025-08-19-08-21-21-915\n"
     ]
    }
   ],
   "source": [
    "###### To check what are the model names available in the Endpoint ########\n",
    "###########################################################################\n",
    "import boto3\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=\"us-east-1\")\n",
    "\n",
    "response = sm_client.list_models(MaxResults=10)\n",
    "for model in response[\"Models\"]:\n",
    "    print(model[\"ModelName\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "918a67fb-91cc-4ad9-b107-2cef28ce8925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Endpoint Config: fraud-endpoint-config-ab\n"
     ]
    }
   ],
   "source": [
    "########### A/B testing Configuration ##########\n",
    "################################################\n",
    "\n",
    "import boto3\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "endpoint_config_name = \"fraud-endpoint-config-ab\"\n",
    "\n",
    "response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"Variant1\",\n",
    "            \"ModelName\": \"fraud-model-v2\",   # your v2 model\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InstanceType\": \"ml.m5.large\",\n",
    "            \"InitialVariantWeight\": 0.7,   # 70% traffic\n",
    "        },\n",
    "        {\n",
    "            \"VariantName\": \"Variant2\",\n",
    "            \"ModelName\": \"fraud-ecr-1908-2025-08-19-08-21-21-915\",   # your ECR model\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InstanceType\": \"ml.m5.large\",\n",
    "            \"InitialVariantWeight\": 0.3,   # 30% traffic\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Created Endpoint Config:\", endpoint_config_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93d63e86-3e52-4fda-82b8-bf1cea464868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Endpoint created: arn:aws:sagemaker:us-east-1:491085388405:endpoint/fraud-endpoint\n"
     ]
    }
   ],
   "source": [
    "###### create or update the endpoint to use this new endpoint config (fraud-endpoint-config-ab)######\n",
    "#####################################################################################################\n",
    "import boto3\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "endpoint_name = \"fraud-endpoint\"\n",
    "\n",
    "response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=\"fraud-endpoint-config-ab\"\n",
    ")\n",
    "\n",
    "print(\"✅ Endpoint created:\", response['EndpointArn'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecab6c4b-e7fe-4ca9-8c34-92b382929b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: {\"predictions\":[0,0]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## Inference using two rows of Sample Data #########\n",
    "##########################################################\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# Create SageMaker runtime client\n",
    "client = boto3.client('sagemaker-runtime', region_name='us-east-1')  # update region if needed\n",
    "\n",
    "# Sample input — should match model's expected feature shape and order\n",
    "# payload = {\n",
    "#     \"inputs\": [[18.0, 1.0, 100987.0, 120870.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0]]\n",
    "# }\n",
    "\n",
    "payload = {\n",
    "    \"inputs\": [\n",
    "        [18.0, 1.0, 100987.0, 120870.0, 2.0, 2.0, 1.0, 1.0, 0.0, 0.0],\n",
    "        [25.0, 0.0, 200000.0, 150000.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0]\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Invoke the deployed endpoint\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName='fraud-ml-endpoint',  # Make sure this matches exactly\n",
    "    Body=json.dumps(payload),\n",
    "    ContentType='application/json'\n",
    ")\n",
    "\n",
    "# Read and decode the prediction\n",
    "result = response['Body'].read().decode('utf-8')\n",
    "print(\"Prediction:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d19edf-56c6-4473-b644-17d11a3d7dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%` not found.\n"
     ]
    }
   ],
   "source": [
    "# file: model_monitoring_dashboard.py\n",
    "%% writefile streamlit_dashboard.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --------------------------\n",
    "# Simulated Functions (replace with real ones later)\n",
    "# --------------------------\n",
    "def load_model_metrics():\n",
    "    \"\"\"Simulate loading model performance metrics (from logs/DB).\"\"\"\n",
    "    data = {\n",
    "        \"timestamp\": pd.date_range(datetime.now() - timedelta(days=30), periods=30),\n",
    "        \"accuracy\": np.random.uniform(0.7, 0.95, 30),\n",
    "        \"f1_score\": np.random.uniform(0.6, 0.9, 30),\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def load_data_drift():\n",
    "    \"\"\"Simulate loading data drift statistics.\"\"\"\n",
    "    features = [\"feature1\", \"feature2\", \"feature3\", \"feature4\"]\n",
    "    drift_scores = np.random.uniform(0, 1, len(features))\n",
    "    return pd.DataFrame({\"feature\": features, \"drift_score\": drift_scores})\n",
    "\n",
    "# --------------------------\n",
    "# Streamlit Dashboard\n",
    "# --------------------------\n",
    "st.set_page_config(page_title=\"MLOps Monitoring Dashboard\", layout=\"wide\")\n",
    "\n",
    "st.title(\"📊 Model & Data Drift Monitoring Dashboard\")\n",
    "\n",
    "# Section 1: Model Performance\n",
    "st.subheader(\"Model Performance Over Time\")\n",
    "metrics_df = load_model_metrics()\n",
    "\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    st.line_chart(metrics_df.set_index(\"timestamp\")[[\"accuracy\"]], height=250)\n",
    "    st.caption(\"Model Accuracy trend\")\n",
    "\n",
    "with col2:\n",
    "    st.line_chart(metrics_df.set_index(\"timestamp\")[[\"f1_score\"]], height=250)\n",
    "    st.caption(\"Model F1-score trend\")\n",
    "\n",
    "# Section 2: Data Drift\n",
    "st.subheader(\"Data Drift by Feature\")\n",
    "drift_df = load_data_drift()\n",
    "\n",
    "st.bar_chart(drift_df.set_index(\"feature\"), height=300)\n",
    "\n",
    "# Section 3: Alerts\n",
    "st.subheader(\"🚨 Alerts\")\n",
    "drift_threshold = 0.7\n",
    "alerts = drift_df[drift_df[\"drift_score\"] > drift_threshold]\n",
    "\n",
    "if not alerts.empty:\n",
    "    st.error(f\"High drift detected in features: {', '.join(alerts['feature'])}\")\n",
    "else:\n",
    "    st.success(\"No significant data drift detected.\")\n",
    "\n",
    "# Section 4: Model Registry (placeholder)\n",
    "st.subheader(\"Model Registry & Versions\")\n",
    "st.write(\"Here you can integrate with SageMaker Model Registry to fetch version info.\")\n",
    "st.table(\n",
    "    pd.DataFrame({\n",
    "        \"Model Version\": [\"v1\", \"v2\", \"v3\"],\n",
    "        \"Deployed At\": [\n",
    "            datetime.now() - timedelta(days=20),\n",
    "            datetime.now() - timedelta(days=10),\n",
    "            datetime.now() - timedelta(days=2),\n",
    "        ],\n",
    "        \"Status\": [\"Archived\", \"Production\", \"Staging\"],\n",
    "    })\n",
    ")\n",
    "\n",
    "st.caption(\"This is a starter dashboard. Integrate it with SageMaker Model Monitor, CloudWatch logs, or your metadata DB.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82860be2-484d-4bfa-b93f-6e487bfb0fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dashboard.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dashboard.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datetime\n",
    "\n",
    "# Simulated function to fetch model metrics\n",
    "def get_model_metrics():\n",
    "    return {\n",
    "        \"accuracy\": np.random.uniform(0.7, 0.99),\n",
    "        \"precision\": np.random.uniform(0.6, 0.95),\n",
    "        \"recall\": np.random.uniform(0.5, 0.9)\n",
    "    }\n",
    "\n",
    "# Simulated function to detect drift\n",
    "def detect_data_drift():\n",
    "    return np.random.choice([True, False], p=[0.2, 0.8])\n",
    "\n",
    "st.title(\"🚀 MLOps Continuous Monitoring Dashboard\")\n",
    "st.markdown(\"Monitoring **Model Performance** and **Data Drift** in Real-Time\")\n",
    "\n",
    "# Model Metrics Section\n",
    "st.header(\"📊 Model Performance\")\n",
    "metrics = get_model_metrics()\n",
    "st.write(\"Latest Metrics:\", metrics)\n",
    "\n",
    "st.line_chart(pd.DataFrame({\n",
    "    \"accuracy\": [metrics[\"accuracy\"]],\n",
    "    \"precision\": [metrics[\"precision\"]],\n",
    "    \"recall\": [metrics[\"recall\"]]\n",
    "}))\n",
    "\n",
    "# Drift Detection Section\n",
    "st.header(\"⚠️ Data Drift Detection\")\n",
    "drift_detected = detect_data_drift()\n",
    "\n",
    "if drift_detected:\n",
    "    st.error(\"Data Drift Detected! 🚨 Retraining may be required.\")\n",
    "else:\n",
    "    st.success(\"No significant drift detected ✅\")\n",
    "\n",
    "# Logs Section\n",
    "st.header(\"📝 Monitoring Logs\")\n",
    "log_data = pd.DataFrame({\n",
    "    \"timestamp\": [datetime.datetime.now()],\n",
    "    \"accuracy\": [metrics[\"accuracy\"]],\n",
    "    \"drift_detected\": [drift_detected]\n",
    "})\n",
    "st.table(log_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9836a316-ce87-4c47-a105-588b56dae058",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fac5178f-7cd0-4cf9-89a5-c6c035d96e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://0.0.0.0:8501\u001b[0m\n",
      "\u001b[0m\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run dashboard.py --server.port 8501 --server.address 0.0.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b681d0f-4cef-40ee-8d62-7e04b7ccdb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  URL: \u001b[0m\u001b[1mhttp://0.0.0.0:8501\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run dashboard.py --server.port 8501 --server.address 0.0.0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec832fc-90c4-4a21-b650-9f4113b4137d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64dc8c6-af01-4273-b9e7-1e4d101e1f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
