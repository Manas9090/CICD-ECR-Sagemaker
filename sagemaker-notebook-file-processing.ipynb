{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e4794c-7b1f-4fdf-8347-e169c1a0af10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.9.9)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (1.38.38)\n",
      "Requirement already satisfied: sqlalchemy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.0.41)\n",
      "Requirement already satisfied: psycopg2==2.9.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from psycopg2-binary) (2.9.9)\n",
      "Requirement already satisfied: botocore<1.39.0,>=1.38.38 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.38.38)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.39.0,>=1.38.38->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.39.0,>=1.38.38->boto3) (2.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.39.0,>=1.38.38->boto3) (1.17.0)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy) (3.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sqlalchemy) (4.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2-binary boto3 sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f1ecc6-b5ba-414c-9c51-71aa8add83ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting supabase\n",
      "  Downloading supabase-2.17.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gotrue==2.12.3 (from supabase)\n",
      "  Downloading gotrue-2.12.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpx<0.29,>=0.26 (from supabase)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting postgrest==1.1.1 (from supabase)\n",
      "  Downloading postgrest-1.1.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting realtime==2.6.0 (from supabase)\n",
      "  Downloading realtime-2.6.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting storage3==0.12.0 (from supabase)\n",
      "  Downloading storage3-0.12.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting supafunc==0.10.1 (from supabase)\n",
      "  Downloading supafunc-0.10.1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gotrue==2.12.3->supabase) (2.9.2)\n",
      "Requirement already satisfied: pyjwt<3.0.0,>=2.10.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gotrue==2.12.3->supabase) (2.10.1)\n",
      "Collecting deprecation<3.0.0,>=2.1.0 (from postgrest==1.1.1->supabase)\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting strenum<0.5.0,>=0.4.9 (from postgrest==1.1.1->supabase)\n",
      "  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pydantic<3,>=1.10 (from gotrue==2.12.3->supabase)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from realtime==2.6.0->supabase) (4.14.0)\n",
      "Collecting websockets<16,>=11 (from realtime==2.6.0->supabase)\n",
      "  Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from storage3==0.12.0->supabase) (2.9.0.post0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deprecation<3.0.0,>=2.1.0->postgrest==1.1.1->supabase) (24.2)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<0.29,>=0.26->supabase) (4.9.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<0.29,>=0.26->supabase) (2025.6.15)\n",
      "Collecting httpcore==1.* (from httpx<0.29,>=0.26->supabase)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<0.29,>=0.26->supabase) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.29,>=0.26->supabase) (0.16.0)\n",
      "Requirement already satisfied: h2<5,>=3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx[http2]<0.29,>=0.26->gotrue==2.12.3->supabase) (4.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue==2.12.3->supabase) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]<0.29,>=0.26->gotrue==2.12.3->supabase) (4.1.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.10->gotrue==2.12.3->supabase) (0.7.0)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.10->gotrue==2.12.3->supabase)\n",
      "  Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.10->gotrue==2.12.3->supabase)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->storage3==0.12.0->supabase) (1.17.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx<0.29,>=0.26->supabase) (1.3.1)\n",
      "Downloading supabase-2.17.0-py3-none-any.whl (17 kB)\n",
      "Downloading gotrue-2.12.3-py3-none-any.whl (44 kB)\n",
      "Downloading postgrest-1.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading realtime-2.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading storage3-0.12.0-py3-none-any.whl (18 kB)\n",
      "Downloading supafunc-0.10.1-py3-none-any.whl (8.0 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
      "Downloading websockets-15.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (181 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: strenum, websockets, typing-inspection, pydantic-core, httpcore, deprecation, pydantic, realtime, httpx, supafunc, storage3, postgrest, gotrue, supabase\n",
      "\u001b[2K  Attempting uninstall: pydantic-core\n",
      "\u001b[2K    Found existing installation: pydantic_core 2.23.4\n",
      "\u001b[2K    Uninstalling pydantic_core-2.23.4:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/14\u001b[0m [pydantic-core]\n",
      "\u001b[2K      Successfully uninstalled pydantic_core-2.23.4━━━━━━━━━━━\u001b[0m \u001b[32m 3/14\u001b[0m [pydantic-core]\n",
      "\u001b[2K  Attempting uninstall: pydantic\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/14\u001b[0m [deprecation]e]\n",
      "\u001b[2K    Found existing installation: pydantic 2.9.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/14\u001b[0m [deprecation]\n",
      "\u001b[2K    Uninstalling pydantic-2.9.2:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/14\u001b[0m [pydantic]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.9.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/14\u001b[0m [pydantic]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/14\u001b[0m [supabase]/14\u001b[0m [gotrue]e]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "safety-schemas 0.0.14 requires pydantic<2.10.0,>=2.6.0, but you have pydantic 2.11.7 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.2.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed deprecation-2.1.0 gotrue-2.12.3 httpcore-1.0.9 httpx-0.28.1 postgrest-1.1.1 pydantic-2.11.7 pydantic-core-2.33.2 realtime-2.6.0 storage3-0.12.0 strenum-0.4.15 supabase-2.17.0 supafunc-0.10.1 typing-inspection-0.4.1 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install supabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56dc3b9b-4eb1-4541-be02-6c60979c70b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Upload to S3 complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(\"Supabase raw response:\", response)\n",
    "# print(\"Supabase data:\", response.data)\n",
    "\n",
    "\n",
    "# print(\"DataFrame shape:\", df.shape)\n",
    "# print(\"DataFrame head:\\n\", df.head())\n",
    "\n",
    "\n",
    "from supabase import create_client, Client\n",
    "import pandas as pd\n",
    "import boto3\n",
    "\n",
    "# Supabase config\n",
    "SUPABASE_URL = \"https://mcgzvjzuqnjstptfrsuj.supabase.co\"\n",
    "SUPABASE_KEY = \"sb_publishable_4vx6B3HjwnEQVwI9SgrJkQ_S32tu5l5\"\n",
    "\n",
    "# Use the service_role key, not anon\n",
    "\n",
    "# Create Supabase client\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "# Fetch data\n",
    "response = supabase.table(\"loan_fraud_analytics\").select(\"*\").execute()\n",
    "df = pd.DataFrame(response.data)\n",
    "\n",
    "# Save as CSV\n",
    "csv_path = \"/tmp/loan_fraud_data.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "# Upload to S3\n",
    "s3 = boto3.client(\"s3\")\n",
    "bucket_name = \"manas-bucket100\"\n",
    "object_key = \"input-file/loan_fraud_data.csv\"\n",
    "\n",
    "s3.upload_file(csv_path, bucket_name, object_key)\n",
    "print(\"✅ Upload to S3 complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d0f014-64b8-4987-8ba5-929b5623f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Features uploaded to s3://manas-bucket100/input-file/loan_fraud_data.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import io\n",
    "\n",
    "# Drop target column\n",
    "df_features = df.drop(columns=['loan_default'])\n",
    "\n",
    "# Convert to CSV buffer\n",
    "csv_buffer = io.StringIO()\n",
    "df_features.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Upload to S3\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'manas-bucket100'  # 🔁 Your bucket name\n",
    "object_key = 'input-file/loan_fraud_data.csv'\n",
    "\n",
    "s3.put_object(Bucket=bucket_name, Key=object_key, Body=csv_buffer.getvalue())\n",
    "\n",
    "print(f\"✅ Features uploaded to s3://{bucket_name}/{object_key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "578f3da4-1160-4ebc-b5e2-e383aa299154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded data from s3://manas-bucket100/input-file/loan_fraud_data.csv\n",
      "📥 Original shape: (1000, 9)\n",
      "🧹 Dropping low-variance/id-like columns: ['loan_id', 'last_delinq_none']\n",
      "📊 Processed shape: (1000, 10)\n",
      "✅ Preprocessed test data saved: processed_test_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10936/2229654881.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].median(), inplace=True)\n",
      "/tmp/ipykernel_10936/2229654881.py:24: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "####### Code for Data processing ########\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import boto3\n",
    "from io import StringIO\n",
    "bucket_name = \"manas-bucket100\"\n",
    "s3_key = \"input-file/loan_fraud_data.csv\"\n",
    "\n",
    "# Step 1: Define S3 download\n",
    "def load_csv_from_s3(bucket_name, file_key):\n",
    "    s3 = boto3.client('s3')\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    df = pd.read_csv(StringIO(content))\n",
    "    print(f\"✅ Loaded data from s3://{bucket_name}/{file_key}\")\n",
    "    return df\n",
    "\n",
    "# Step 2: Handle missing values\n",
    "def handle_missing_values(df):\n",
    "    df = df.copy()\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "        else:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    return df\n",
    "\n",
    "# Step 3: Handle outliers\n",
    "def handle_outliers(df):\n",
    "    df = df.copy()\n",
    "    for col in df.select_dtypes(include=np.number).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - 1.5 * IQR\n",
    "        upper = Q3 + 1.5 * IQR\n",
    "        df[col] = np.where(df[col] < lower, lower,\n",
    "                  np.where(df[col] > upper, upper, df[col]))\n",
    "    return df\n",
    "\n",
    "# Step 4: Create dummies\n",
    "def create_dummies(df):\n",
    "    df = pd.get_dummies(df, drop_first=True, dtype=int)\n",
    "    return df\n",
    "\n",
    "# Step 5: Drop low-variance and ID-like columns\n",
    "def drop_low_variance_and_id_columns(df, threshold=0.95):\n",
    "    df = df.copy()\n",
    "    drop_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() <= 1:\n",
    "            drop_cols.append(col)\n",
    "        else:\n",
    "            top_freq_ratio = df[col].value_counts(normalize=True).values[0]\n",
    "            if top_freq_ratio >= threshold:\n",
    "                drop_cols.append(col)\n",
    "\n",
    "    id_like_cols = [col for col in df.columns if col.lower() == 'id'\n",
    "                    or col.lower().startswith('id')\n",
    "                    or col.lower().endswith('id')\n",
    "                    or '_id' in col.lower()\n",
    "                    or 'id_' in col.lower()]\n",
    "    \n",
    "    drop_cols = list(set(drop_cols + id_like_cols))\n",
    "\n",
    "    if drop_cols:\n",
    "        print(f\"🧹 Dropping low-variance/id-like columns: {drop_cols}\")\n",
    "        df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Step 6: Run all preprocessing\n",
    "def preprocess_data(df):\n",
    "    df = drop_low_variance_and_id_columns(df, threshold=0.95)\n",
    "    df = handle_missing_values(df)\n",
    "    df = handle_outliers(df)\n",
    "    df = create_dummies(df)\n",
    "    return df\n",
    "\n",
    "# MAIN execution inside SageMaker\n",
    "def main():\n",
    "    bucket_name = 'manas-bucket100'\n",
    "    file_key = 'input-file/loan_fraud_data.csv'  # full path in S3 bucket\n",
    "\n",
    "    df = load_csv_from_s3(bucket_name, file_key)\n",
    "    print(f\"📥 Original shape: {df.shape}\")\n",
    "\n",
    "    df = preprocess_data(df)\n",
    "    print(f\"📊 Processed shape: {df.shape}\")\n",
    "\n",
    "    # Save to local file or upload to S3 if needed\n",
    "    processed_file = \"processed_test_data.csv\"\n",
    "    df.to_csv(processed_file, index=False)\n",
    "    print(f\"✅ Preprocessed test data saved: {processed_file}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Run if in script mode\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dba428-07a2-4c63-b874-e3fa2e1903af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543bb661-824e-4f11-b8dd-5ed3591315c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea586f39-17ca-45ee-a6df-e04fe1876628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d7fa82-1a43-4c6f-81dd-c9a50903251d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92f9c2e-9fa4-4b8d-8972-e6ea36913180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
